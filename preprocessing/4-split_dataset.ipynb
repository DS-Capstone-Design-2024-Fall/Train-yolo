{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_ds length :  6844\n",
      "val_ds length :  1467\n",
      "test_ds length :  1467\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import supervision as sv\n",
    "\n",
    "root_path = \"D:/Downloads/street-facilities-selected\"\n",
    "\n",
    "# 데이터셋 로드\n",
    "ds = sv.DetectionDataset.from_yolo(\n",
    "    images_directory_path=f\"{root_path}/transformed-images\",\n",
    "    annotations_directory_path=f\"{root_path}/transformed-labels-txt\",\n",
    "    data_yaml_path=f\"{root_path}/street-facilities.yaml\"\n",
    ")\n",
    "\n",
    "# 데이터셋 분리 (train 70%, val 15 % test 15%)\n",
    "train_ds, val_test_ds = ds.split(split_ratio=0.7, random_state=1014, shuffle=True)\n",
    "val_ds, test_ds = val_test_ds.split(split_ratio=0.5, random_state=535, shuffle=True)\n",
    "\n",
    "print(\"train_ds length : \", len(train_ds))\n",
    "print(\"val_ds length : \", len(val_ds))\n",
    "print(\"test_ds length : \", len(test_ds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 분할된 데이터셋 클래스 분포 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class 0 (점자블록 파손부), 1(보도블럭 파손부), 2(자전거도로 파손부)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 22\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass 0 (점자블록 파손부), 1(보도블럭 파손부), 2(자전거도로 파손부)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ds \u001b[38;5;129;01min\u001b[39;00m [train_ds, val_ds, test_ds]:\n\u001b[1;32m---> 22\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mcount_classes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mds\u001b[49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[1;32mIn[2], line 7\u001b[0m, in \u001b[0;36mcount_classes\u001b[1;34m(dataset)\u001b[0m\n\u001b[0;32m      4\u001b[0m n_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(dataset\u001b[38;5;241m.\u001b[39mclasses)\n\u001b[0;32m      6\u001b[0m count \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(n_classes, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mint16)\n\u001b[1;32m----> 7\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mannotation\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__iter__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# 사진 하나에 존재하는 0개 이상의 class object 들을 각각 센다\u001b[39;49;00m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# print(annotation) \u001b[39;49;00m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mannotation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_id\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcount\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\myvenv\\Lib\\site-packages\\supervision\\dataset\\core.py:154\u001b[0m, in \u001b[0;36mDetectionDataset.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;124;03mIterate over the images and annotations in the dataset.\u001b[39;00m\n\u001b[0;32m    147\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;124;03m        the image data, and its corresponding annotation.\u001b[39;00m\n\u001b[0;32m    152\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m)):\n\u001b[1;32m--> 154\u001b[0m     image_path, image, annotation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    155\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m image_path, image, annotation\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\myvenv\\Lib\\site-packages\\supervision\\dataset\\core.py:140\u001b[0m, in \u001b[0;36mDetectionDataset.__getitem__\u001b[1;34m(self, i)\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;124;03mReturns:\u001b[39;00m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;124;03m    Tuple[str, np.ndarray, Detections]: The image path, image data,\u001b[39;00m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;124;03m        and its corresponding annotation at index i.\u001b[39;00m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    139\u001b[0m image_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_paths[i]\n\u001b[1;32m--> 140\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    141\u001b[0m annotation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mannotations[image_path]\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m image_path, image, annotation\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\myvenv\\Lib\\site-packages\\supervision\\dataset\\core.py:128\u001b[0m, in \u001b[0;36mDetectionDataset._get_image\u001b[1;34m(self, image_path)\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_images_in_memory:\n\u001b[0;32m    127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_images_in_memory[image_path]\n\u001b[1;32m--> 128\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def count_classes(dataset : sv.DetectionDataset):\n",
    "    n_classes = len(dataset.classes)\n",
    "    \n",
    "    count = np.zeros(n_classes, dtype=np.int16)\n",
    "    for _, _, annotation in dataset.__iter__():\n",
    "        # 사진 하나에 존재하는 0개 이상의 class object 들을 각각 센다\n",
    "        # print(annotation) \n",
    "        for label in annotation.class_id:\n",
    "            count[label] += 1\n",
    "\n",
    "    return count\n",
    "\n",
    "# names:\n",
    "#   0: braille-block-defect\n",
    "#   1: sidewalk-block-defect\n",
    "#   2: bicycle-road-defect\n",
    "\n",
    "print(\"class 0 (점자블록 파손부), 1(보도블럭 파손부), 2(자전거도로 파손부)\")\n",
    "for ds in [train_ds, val_ds, test_ds]:\n",
    "    print(count_classes(ds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 6844\n",
      "201 / 6844\n",
      "401 / 6844\n",
      "601 / 6844\n",
      "801 / 6844\n",
      "1001 / 6844\n",
      "1201 / 6844\n",
      "1401 / 6844\n",
      "1601 / 6844\n",
      "1801 / 6844\n",
      "2001 / 6844\n",
      "2201 / 6844\n",
      "2401 / 6844\n",
      "2601 / 6844\n",
      "2801 / 6844\n",
      "3001 / 6844\n",
      "3201 / 6844\n",
      "3401 / 6844\n",
      "3601 / 6844\n",
      "3801 / 6844\n",
      "4001 / 6844\n",
      "4201 / 6844\n",
      "4401 / 6844\n",
      "4601 / 6844\n",
      "4801 / 6844\n",
      "5001 / 6844\n",
      "5201 / 6844\n",
      "5401 / 6844\n",
      "5601 / 6844\n",
      "5801 / 6844\n",
      "6001 / 6844\n",
      "6201 / 6844\n",
      "6401 / 6844\n",
      "6601 / 6844\n",
      "6801 / 6844\n",
      "1 / 1467\n",
      "201 / 1467\n",
      "401 / 1467\n",
      "601 / 1467\n",
      "801 / 1467\n",
      "1001 / 1467\n",
      "1201 / 1467\n",
      "1401 / 1467\n",
      "1 / 1467\n",
      "201 / 1467\n",
      "401 / 1467\n",
      "601 / 1467\n",
      "801 / 1467\n",
      "1001 / 1467\n",
      "1201 / 1467\n",
      "1401 / 1467\n",
      "Train/Validation/Test 데이터셋 저장 완료.\n"
     ]
    }
   ],
   "source": [
    "# 저장할 디렉토리 경로 설정\n",
    "root_path = \"D:/Downloads/street-facilities-5\"\n",
    "train_images_dir = f\"{root_path}/images/train\"\n",
    "train_labels_dir = f\"{root_path}/labels/train\"\n",
    "\n",
    "val_images_dir = f\"{root_path}/images/val\"\n",
    "val_labels_dir = f\"{root_path}/labels/val\"\n",
    "\n",
    "test_images_dir = f\"{root_path}/images/test\"\n",
    "test_labels_dir = f\"{root_path}/labels/test\"\n",
    "\n",
    "# 디렉토리 생성 (존재하지 않는 경우에만)\n",
    "os.makedirs(train_images_dir, exist_ok=True)\n",
    "os.makedirs(train_labels_dir, exist_ok=True)\n",
    "\n",
    "os.makedirs(val_images_dir, exist_ok=True)\n",
    "os.makedirs(val_labels_dir, exist_ok=True)\n",
    "\n",
    "os.makedirs(test_images_dir, exist_ok=True)\n",
    "os.makedirs(test_labels_dir, exist_ok=True)\n",
    "\n",
    "# DetectionDataset 객체의 이미지 및 라벨을 복사하여 저장\n",
    "def save_dataset(dataset, images_dir_to_save, labels_dir_to_save):\n",
    "    i = 1\n",
    "    total = len(dataset)\n",
    "    for image_path, image, annotation in dataset.__iter__():\n",
    "        if i % 200 == 1 : print(f\"{i} / {total}\")\n",
    "        # image_path : path/image_filename.jpg or .jpeg\n",
    "        image_filename = os.path.basename(image_path) # 이미지 파일 이름\n",
    "        label_filename = os.path.splitext(image_filename)[0] + \".txt\" # 확장자명만 변경 (.jpg or .jpeg -> .txt)\n",
    "\n",
    "        # label_path 조합\n",
    "        label_path = \"\\\\\".join(image_path.split(\"\\\\\")[:-2] + [\"transformed-labels-txt\", label_filename])\n",
    "        \n",
    "        # 이미지 및 라벨을 각각 지정된 폴더로 복사\n",
    "        shutil.copy(image_path, os.path.join(images_dir_to_save, image_filename))\n",
    "        shutil.copy(label_path, os.path.join(labels_dir_to_save, label_filename))\n",
    "        i += 1\n",
    "\n",
    "\n",
    "# train 데이터셋 저장\n",
    "save_dataset(train_ds, train_images_dir, train_labels_dir)\n",
    "# validation 데이터셋 저장\n",
    "save_dataset(val_ds, val_images_dir, val_labels_dir)\n",
    "# test 데이터셋 저장\n",
    "save_dataset(test_ds, test_images_dir, test_labels_dir)\n",
    "\n",
    "print(\"Train/Validation/Test 데이터셋 저장 완료.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "저장 완료 후 데이터셋 분포 빠르게 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 13689\n",
      "301 / 13689\n",
      "601 / 13689\n",
      "901 / 13689\n",
      "1201 / 13689\n",
      "1501 / 13689\n",
      "1801 / 13689\n",
      "2101 / 13689\n",
      "2401 / 13689\n",
      "2701 / 13689\n",
      "3001 / 13689\n",
      "3301 / 13689\n",
      "3601 / 13689\n",
      "3901 / 13689\n",
      "4201 / 13689\n",
      "4501 / 13689\n",
      "4801 / 13689\n",
      "5101 / 13689\n",
      "5401 / 13689\n",
      "5701 / 13689\n",
      "6001 / 13689\n",
      "6301 / 13689\n",
      "6601 / 13689\n",
      "6901 / 13689\n",
      "7201 / 13689\n",
      "7501 / 13689\n",
      "7801 / 13689\n",
      "8101 / 13689\n",
      "8401 / 13689\n",
      "8701 / 13689\n",
      "9001 / 13689\n",
      "9301 / 13689\n",
      "9601 / 13689\n",
      "9901 / 13689\n",
      "10201 / 13689\n",
      "10501 / 13689\n",
      "10801 / 13689\n",
      "11101 / 13689\n",
      "11401 / 13689\n",
      "11701 / 13689\n",
      "12001 / 13689\n",
      "12301 / 13689\n",
      "12601 / 13689\n",
      "12901 / 13689\n",
      "13201 / 13689\n",
      "13501 / 13689\n",
      "1 / 2933\n",
      "301 / 2933\n",
      "601 / 2933\n",
      "901 / 2933\n",
      "1201 / 2933\n",
      "1501 / 2933\n",
      "1801 / 2933\n",
      "2101 / 2933\n",
      "2401 / 2933\n",
      "2701 / 2933\n",
      "1 / 2934\n",
      "301 / 2934\n",
      "601 / 2934\n",
      "901 / 2934\n",
      "1201 / 2934\n",
      "1501 / 2934\n",
      "1801 / 2934\n",
      "2101 / 2934\n",
      "2401 / 2934\n",
      "2701 / 2934\n",
      "\n",
      "train\n",
      "[ 7667 10625  7542]\n",
      "negative sample\n",
      "[ 507 1525 1272]\n",
      "val\n",
      "[1506 2451 1513]\n",
      "negative sample\n",
      "[119 342 277]\n",
      "test\n",
      "[1619 2268 1739]\n",
      "negative sample\n",
      "[102 299 281]\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "\n",
    "root_path = \"D:/Downloads/street-facilities-5-db/labels\"\n",
    "\n",
    "sub_path = [\"train\", \"val\", \"test\"]\n",
    "\n",
    "class_mapping = {\n",
    "    9 : 0,\n",
    "    12: 1, \n",
    "    13 : 2,\n",
    "}\n",
    "\n",
    "cnt_classes = np.zeros((3,3), dtype=int)\n",
    "negative_samples = np.zeros((3,3), dtype=int)\n",
    "\n",
    "for k, sub in enumerate(sub_path):\n",
    "    label_dir = os.path.join(root_path, sub)\n",
    "\n",
    "    labels = [label for label in os.listdir(label_dir) if label.endswith('.txt')]\n",
    "    total_cnt = len(labels)\n",
    "\n",
    "    for i, label in enumerate(labels):\n",
    "        if i % 300 == 0 :\n",
    "            print(f\"{i+1} / {total_cnt}\")\n",
    "\n",
    "        ctype = int(label.split(\"_\")[1])\n",
    "\n",
    "        # if (int(label.split(\"_\")[2]) == 0): # 정상(0) 라벨\n",
    "        #     ctype = int(label.split(\"_\")[1])\n",
    "        #     negative_samples[k][class_mapping[ctype]] += 1\n",
    "\n",
    "        label_path = os.path.join(label_dir, label)\n",
    "        # 정상 라벨 데이터\n",
    "        if (os.path.isfile(label_path) and os.path.getsize(label_path) == 0):\n",
    "            negative_samples[k][class_mapping[ctype]] += 1\n",
    "            continue\n",
    "\n",
    "        # 불량 라벨 데이터\n",
    "        with open(label_path, \"r+\", encoding=\"utf-8\") as f:\n",
    "            # 기존 내용 읽기 및 수정        \n",
    "            for line in f:\n",
    "                elems = line.split(\" \")\n",
    "                # 클래스 분포 집계 (0, 1, 2)\n",
    "                # cnt_classes[k][class_mapping(ctype)] += 1\n",
    "                cnt_classes[k][int(float(elems[0]))] += 1\n",
    "\n",
    "print()\n",
    "for i, type in enumerate(sub_path):\n",
    "    print(type)\n",
    "    print(cnt_classes[i])\n",
    "    print(\"negative sample\")\n",
    "    print(negative_samples[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
